{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10 class image classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1cyrJzg79aw6NfpLuWQ6tEZ6fLXX9CDTq",
      "authorship_tag": "ABX9TyPC2BOgE9UOo/xbMhqbfDBY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohankavari/DeepLearning/blob/main/10_class_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gc43cOlrHUq"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdUdzv2w17bu",
        "outputId": "0c65bd4d-c5fb-4d81-d330-d5db97d348aa"
      },
      "source": [
        "(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()\n",
        "X_train.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "170508288/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "VP5eImNP2BsV",
        "outputId": "ca23c450-b852-400e-960b-97892e36a8b5"
      },
      "source": [
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9f258539d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiHql9GY2Yxz"
      },
      "source": [
        "y_train = y_train.reshape(-1,)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCBnKsm82ZV9"
      },
      "source": [
        "y_test = y_test.reshape(-1,)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zeAyNVb2iem"
      },
      "source": [
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw7XK-Hx2_l_",
        "outputId": "c9b71559-20f4-4429-bdb7-5d312925385a"
      },
      "source": [
        "ann = models.Sequential([\n",
        "        layers.Flatten(input_shape=(32,32,3)),\n",
        "        layers.Dense(3000, activation='relu'),\n",
        "        layers.Dense(1000, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')    \n",
        "    ])\n",
        "\n",
        "ann.compile(optimizer='SGD',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "ann.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8137 - accuracy: 0.3535\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6214 - accuracy: 0.4295\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5415 - accuracy: 0.4563\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4811 - accuracy: 0.4778\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4316 - accuracy: 0.4960\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3868 - accuracy: 0.5131\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3520 - accuracy: 0.5224\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3166 - accuracy: 0.5389\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2808 - accuracy: 0.5509\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2520 - accuracy: 0.5597\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2230 - accuracy: 0.5725\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1937 - accuracy: 0.5816\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1661 - accuracy: 0.5933\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1376 - accuracy: 0.6012\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1128 - accuracy: 0.6134\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0864 - accuracy: 0.6201\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0601 - accuracy: 0.6282\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0335 - accuracy: 0.6407\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0087 - accuracy: 0.6493\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9833 - accuracy: 0.6579\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9577 - accuracy: 0.6688\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9318 - accuracy: 0.6799\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9046 - accuracy: 0.6879\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8803 - accuracy: 0.6975\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8575 - accuracy: 0.7039\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8307 - accuracy: 0.7131\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8061 - accuracy: 0.7238\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7793 - accuracy: 0.7328\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7553 - accuracy: 0.7420\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7292 - accuracy: 0.7511\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7077 - accuracy: 0.7587\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6824 - accuracy: 0.7694\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6623 - accuracy: 0.7779\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6313 - accuracy: 0.7876\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6091 - accuracy: 0.7981\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5861 - accuracy: 0.8057\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5612 - accuracy: 0.8129\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5371 - accuracy: 0.8221\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5163 - accuracy: 0.8304\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4956 - accuracy: 0.8363\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4701 - accuracy: 0.8469\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4508 - accuracy: 0.8539\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4332 - accuracy: 0.8602\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4075 - accuracy: 0.8694\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3890 - accuracy: 0.8771\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3701 - accuracy: 0.8839\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3470 - accuracy: 0.8924\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3318 - accuracy: 0.8980\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3111 - accuracy: 0.9078\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2962 - accuracy: 0.9100\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2818 - accuracy: 0.9162\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2643 - accuracy: 0.9232\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2481 - accuracy: 0.9287\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2351 - accuracy: 0.9337\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2209 - accuracy: 0.9388\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2061 - accuracy: 0.9423\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1934 - accuracy: 0.9468\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1762 - accuracy: 0.9538\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1708 - accuracy: 0.9560\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1563 - accuracy: 0.9601\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1478 - accuracy: 0.9627\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1391 - accuracy: 0.9651\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1274 - accuracy: 0.9694\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1197 - accuracy: 0.9719\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1131 - accuracy: 0.9743\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1027 - accuracy: 0.9780\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0957 - accuracy: 0.9796\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0871 - accuracy: 0.9818\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0822 - accuracy: 0.9842\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0754 - accuracy: 0.9855\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0734 - accuracy: 0.9859\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0691 - accuracy: 0.9872\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0613 - accuracy: 0.9898\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0566 - accuracy: 0.9903\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0499 - accuracy: 0.9922\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0528 - accuracy: 0.9911\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0422 - accuracy: 0.9946\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0389 - accuracy: 0.9947\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0372 - accuracy: 0.9952\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0363 - accuracy: 0.9955\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0315 - accuracy: 0.9964\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0290 - accuracy: 0.9968\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0292 - accuracy: 0.9967\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0244 - accuracy: 0.9978\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0237 - accuracy: 0.9979\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0221 - accuracy: 0.9983\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0219 - accuracy: 0.9980\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0465 - accuracy: 0.9906\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0320 - accuracy: 0.9959\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0189 - accuracy: 0.9986\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0171 - accuracy: 0.9990\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0158 - accuracy: 0.9991\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0156 - accuracy: 0.9989\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0139 - accuracy: 0.9994\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0127 - accuracy: 0.9996\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0122 - accuracy: 0.9996\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0123 - accuracy: 0.9994\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0117 - accuracy: 0.9994\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0106 - accuracy: 0.9997\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0104 - accuracy: 0.9997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9ed80d1c10>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUo9GuG53UpF",
        "outputId": "524f55a3-b670-4918-f773-96cafb363966"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "import numpy as np\n",
        "y_pred = ann.predict(X_test)\n",
        "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
        "\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.65      0.66      1000\n",
            "           1       0.70      0.69      0.69      1000\n",
            "           2       0.48      0.50      0.49      1000\n",
            "           3       0.42      0.42      0.42      1000\n",
            "           4       0.52      0.51      0.52      1000\n",
            "           5       0.48      0.51      0.49      1000\n",
            "           6       0.65      0.62      0.64      1000\n",
            "           7       0.67      0.62      0.65      1000\n",
            "           8       0.66      0.74      0.70      1000\n",
            "           9       0.64      0.61      0.63      1000\n",
            "\n",
            "    accuracy                           0.59     10000\n",
            "   macro avg       0.59      0.59      0.59     10000\n",
            "weighted avg       0.59      0.59      0.59     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JTRkLnp70uh",
        "outputId": "0252a530-61d0-4e05-d4f4-78369ca6d79f"
      },
      "source": [
        "\n",
        "cnn = models.Sequential([\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "cnn.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "cnn.fit(X_train, y_train, epochs=50,validation_data=(X_test,y_test))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4565 - accuracy: 0.4766 - val_loss: 1.2424 - val_accuracy: 0.5574\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1132 - accuracy: 0.6119 - val_loss: 1.0585 - val_accuracy: 0.6270\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9838 - accuracy: 0.6594 - val_loss: 0.9896 - val_accuracy: 0.6553\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8966 - accuracy: 0.6880 - val_loss: 0.9986 - val_accuracy: 0.6583\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8326 - accuracy: 0.7089 - val_loss: 0.9123 - val_accuracy: 0.6877\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7761 - accuracy: 0.7317 - val_loss: 0.9201 - val_accuracy: 0.6872\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7297 - accuracy: 0.7464 - val_loss: 0.9514 - val_accuracy: 0.6784\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6879 - accuracy: 0.7613 - val_loss: 0.9000 - val_accuracy: 0.6958\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6470 - accuracy: 0.7753 - val_loss: 0.9374 - val_accuracy: 0.6960\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6067 - accuracy: 0.7893 - val_loss: 0.9380 - val_accuracy: 0.6882\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5805 - accuracy: 0.7982 - val_loss: 0.9924 - val_accuracy: 0.6829\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5442 - accuracy: 0.8089 - val_loss: 1.0226 - val_accuracy: 0.6844\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5194 - accuracy: 0.8189 - val_loss: 1.0104 - val_accuracy: 0.6948\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4917 - accuracy: 0.8266 - val_loss: 1.0441 - val_accuracy: 0.6840\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4683 - accuracy: 0.8357 - val_loss: 1.0434 - val_accuracy: 0.6953\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4416 - accuracy: 0.8425 - val_loss: 1.0528 - val_accuracy: 0.6922\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4209 - accuracy: 0.8485 - val_loss: 1.0918 - val_accuracy: 0.6868\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3936 - accuracy: 0.8587 - val_loss: 1.1531 - val_accuracy: 0.6778\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3736 - accuracy: 0.8668 - val_loss: 1.2063 - val_accuracy: 0.6825\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3585 - accuracy: 0.8725 - val_loss: 1.2105 - val_accuracy: 0.6834\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3347 - accuracy: 0.8804 - val_loss: 1.3482 - val_accuracy: 0.6710\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3169 - accuracy: 0.8857 - val_loss: 1.3577 - val_accuracy: 0.6802\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3071 - accuracy: 0.8897 - val_loss: 1.4061 - val_accuracy: 0.6723\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2866 - accuracy: 0.8965 - val_loss: 1.4956 - val_accuracy: 0.6708\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2724 - accuracy: 0.9024 - val_loss: 1.4972 - val_accuracy: 0.6710\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2613 - accuracy: 0.9064 - val_loss: 1.5612 - val_accuracy: 0.6691\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2479 - accuracy: 0.9101 - val_loss: 1.6648 - val_accuracy: 0.6703\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2337 - accuracy: 0.9147 - val_loss: 1.6666 - val_accuracy: 0.6732\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2280 - accuracy: 0.9168 - val_loss: 1.7349 - val_accuracy: 0.6710\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2197 - accuracy: 0.9209 - val_loss: 1.8019 - val_accuracy: 0.6640\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2034 - accuracy: 0.9261 - val_loss: 1.9719 - val_accuracy: 0.6617\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1917 - accuracy: 0.9299 - val_loss: 1.9483 - val_accuracy: 0.6629\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1931 - accuracy: 0.9291 - val_loss: 2.0449 - val_accuracy: 0.6625\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1829 - accuracy: 0.9331 - val_loss: 1.9997 - val_accuracy: 0.6678\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1743 - accuracy: 0.9368 - val_loss: 2.1619 - val_accuracy: 0.6740\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1741 - accuracy: 0.9367 - val_loss: 2.1924 - val_accuracy: 0.6559\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1611 - accuracy: 0.9407 - val_loss: 2.2172 - val_accuracy: 0.6655\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1606 - accuracy: 0.9415 - val_loss: 2.3155 - val_accuracy: 0.6607\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1490 - accuracy: 0.9459 - val_loss: 2.3180 - val_accuracy: 0.6602\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1499 - accuracy: 0.9467 - val_loss: 2.3814 - val_accuracy: 0.6578\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1378 - accuracy: 0.9490 - val_loss: 2.4708 - val_accuracy: 0.6493\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1459 - accuracy: 0.9465 - val_loss: 2.4874 - val_accuracy: 0.6608\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1379 - accuracy: 0.9498 - val_loss: 2.5109 - val_accuracy: 0.6595\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1321 - accuracy: 0.9521 - val_loss: 2.7248 - val_accuracy: 0.6494\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1314 - accuracy: 0.9525 - val_loss: 2.6675 - val_accuracy: 0.6584\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1256 - accuracy: 0.9539 - val_loss: 2.7496 - val_accuracy: 0.6591\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1289 - accuracy: 0.9543 - val_loss: 2.7993 - val_accuracy: 0.6553\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1231 - accuracy: 0.9565 - val_loss: 2.8155 - val_accuracy: 0.6574\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1167 - accuracy: 0.9582 - val_loss: 2.8778 - val_accuracy: 0.6493\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1122 - accuracy: 0.9598 - val_loss: 2.9717 - val_accuracy: 0.6577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9e75274a50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwR4fvDR8vZg",
        "outputId": "a02259c5-01d3-459d-f0b3-f7a05ff9311b"
      },
      "source": [
        "y_pred = cnn.predict(X_test)\n",
        "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
        "\n",
        "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.69      0.68      1000\n",
            "           1       0.74      0.81      0.77      1000\n",
            "           2       0.53      0.57      0.55      1000\n",
            "           3       0.46      0.41      0.44      1000\n",
            "           4       0.61      0.56      0.58      1000\n",
            "           5       0.57      0.56      0.57      1000\n",
            "           6       0.73      0.76      0.74      1000\n",
            "           7       0.72      0.69      0.70      1000\n",
            "           8       0.77      0.78      0.77      1000\n",
            "           9       0.74      0.75      0.75      1000\n",
            "\n",
            "    accuracy                           0.66     10000\n",
            "   macro avg       0.65      0.66      0.66     10000\n",
            "weighted avg       0.65      0.66      0.66     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}